{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1. Statistics: The science of collecting, organizing, analyzing, and interpreting data.\n",
    "\n",
    "2. Two main branches:\n",
    "   - Descriptive statistics: Organizing and summarizing data\n",
    "   - Inferential statistics: Using sample data to draw conclusions about a population\n",
    "\n",
    "3. Key terms:\n",
    "   - Population: The complete set of all items or individuals under study\n",
    "   - Sample: A subset of the population, used to make inferences about the whole\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1. Simple Random Sampling:\n",
    "   - Every member of the population has an equal chance of being selected\n",
    "   - Unbiased, but can be impractical for large populations\n",
    "\n",
    "2. Stratified Sampling:\n",
    "   - Population is divided into non-overlapping groups (strata)\n",
    "   - Samples are then taken from each stratum\n",
    "   - Ensures representation of all subgroups\n",
    "\n",
    "3. Systematic Sampling:\n",
    "   - Selecting every Nth individual from the population\n",
    "   - N is determined by dividing population size by desired sample size\n",
    "   - Easy to implement but can introduce bias if there's a pattern in the data\n",
    "\n",
    "4. Convenience Sampling:\n",
    "   - Selecting readily available individuals\n",
    "   - Quick and easy, but often leads to bias\n",
    "   - Not representative of the entire population\n",
    "\n",
    " \n",
    "\n",
    "1. Sampling techniques are used for several important reasons:\n",
    "\n",
    "- Cost-effectiveness: Studying an entire population can be prohibitively expensive and time-consuming. Sampling allows researchers to gather meaningful data at a fraction of the cost.\n",
    "- Time efficiency: Collecting data from a sample is much faster than surveying an entire population, enabling quicker decision-making and more timely research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables:\n",
    "    Here's a concise overview of variables and their types in statistics:\n",
    "\n",
    "Variables in statistics are characteristics or attributes that can be measured or observed. They are typically classified into two main categories:\n",
    "\n",
    "1. Qualitative (Categorical) Variables:\n",
    "   - Nominal: No natural order (e.g., colors, gender)\n",
    "   - Ordinal: Have a natural order (e.g., education levels)\n",
    "\n",
    "2. Quantitative (Numerical) Variables:\n",
    "   - Discrete: Countable, whole numbers (e.g., number of children)\n",
    "   - Continuous: Can take any value within a range (e.g., height, weight)\n",
    "\n",
    "Additionally, variables can be classified as:\n",
    "- Independent: Manipulated or controlled in a study\n",
    "- Dependent: Observed or measured outcomes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Frequency Distribution\n",
    "   **1.1 Discrete Data**\n",
    "   - **Bar Graph**  \n",
    "     - In addition to showing frequency, the spacing between bars emphasizes that the data is discrete (non-continuous). Bar graphs can also be grouped or stacked to compare multiple categories.\n",
    "  \n",
    "   **1.2 Continuous Data**\n",
    "   - **Histogram (Probability Density Function)**\n",
    "        - The choice of bin width can significantly affect the shape of the histogram. Too wide a bin can obscure important details, while too narrow a bin can introduce noise.\n",
    "        - Useful for showing distributions like normal or skewed distributions in continuous datasets.\n",
    "        Probability Density Function (PDF)\n",
    "        - PDFs represent the continuous counterpart of probability mass functions (PMF) used for discrete data.\n",
    "        - Key property: the total area under a PDF equals 1, which corresponds to the total probability.\n",
    "        - PDFs are integral in modeling phenomena like the normal distribution (bell curve), exponential distributions, etc.\n",
    "        - Useful in statistical modeling, hypothesis testing, and simulations (e.g., Monte Carlo methods).\n",
    "\n",
    "\n",
    "   - **Kernel Density Estimation (KDE)**\n",
    "     - KDE smooths the data by placing a kernel (usually a Gaussian function) at each data point, which helps visualize the distribution without the discrete jumps of histograms. \n",
    "     - Bandwidth (smoothing parameter) plays a crucial role in balancing smoothness with the level of detail in the estimate.\n",
    "\n",
    "\n",
    "#### MEASURE OF DATA OR COMPARE TWO DATAS :\n",
    "###  Measures of Central Tendency\n",
    "   **3.1 Mean**  \n",
    "   - It’s the most commonly used measure, but outliers can skew it. In financial datasets (e.g., income), the mean can be misleading due to extreme values.\n",
    "    Certainly. Here are the formulas for population mean and sample mean with their notations:\n",
    "\n",
    "Population Mean:\n",
    "μ = (Σ X) / N\n",
    "\n",
    "Where:\n",
    "μ (mu) = population mean\n",
    "Σ (sigma) = sum of\n",
    "X = each value in the population\n",
    "N = total number of values in the population\n",
    "\n",
    "Sample Mean:\n",
    "x̄ = (Σ x) / n\n",
    "\n",
    "Where:\n",
    "x̄ (x-bar) = sample mean\n",
    "Σ (sigma) = sum of\n",
    "x = each value in the sample\n",
    "n = number of values in the sample\n",
    "\n",
    "   **3.2 Median**  \n",
    "   - Particularly useful in highly skewed distributions (e.g., real estate prices). The median can often represent the \"typical\" value better than the mean in such cases.\n",
    "  \n",
    "   **3.3 Mode**  \n",
    "   - Mode is particularly useful for nominal data, such as identifying the most common category in survey responses.\n",
    "   - In continuous data, a distribution can have multiple modes, suggesting the presence of clusters within the data.\n",
    "\n",
    "### Measures of Dispersion\n",
    "   **4.1 Range**  \n",
    "   - While easy to compute, the range ignores the distribution of values within the dataset. Two datasets with the same range can have different shapes and spread of data.\n",
    "\n",
    "   **4.2 Interquartile Range (IQR)**  \n",
    "   - The IQR is particularly useful for identifying outliers, which are defined as values that fall below Q1 – 1.5*IQR or above Q3 + 1.5*IQR. This measure is often visualized using box plots.\n",
    "   \n",
    "   **4.3 Variance**  \n",
    "   - Variance quantifies the degree to which each data point deviates from the mean. It is the basis for many advanced statistical techniques, such as regression and machine learning models (e.g., in loss functions).\n",
    "   \n",
    "   **4.4 Standard Deviation**  \n",
    "   - A small standard deviation indicates that data points are generally close to the mean, while a larger standard deviation indicates a wider spread. It is widely used in finance (e.g., for measuring stock price volatility).\n",
    "   \n",
    "### Comparing Datasets\n",
    "   - When comparing datasets, besides central tendency (mean, median), and dispersion (variance, standard deviation), skewness and kurtosis also become relevant.\n",
    "     - **Skewness** indicates the symmetry of the data distribution. Positive skew means the tail is on the right, and negative skew means it’s on the left.\n",
    "     - **Kurtosis** indicates the \"tailedness\" of the distribution. High kurtosis means more data is in the tails (outliers), while low kurtosis means the data is more evenly distributed around the mean.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! Here are short notes on each topic:\n",
    "\n",
    "### 1. **A/B Testing**\n",
    "- **Definition**: Comparing two versions (A and B) of a variable to determine which performs better.\n",
    "- **Application**: Used in marketing, UX design, and product optimization.\n",
    "- **Key Points**:\n",
    "  - **Control Group**: Version A (baseline).\n",
    "  - **Treatment Group**: Version B (variant).\n",
    "  - **Objective**: Measure impact on specific outcomes (e.g., conversion rate).\n",
    "\n",
    "### 2. **SUTVA (Stable Unit Treatment Value Assumption)**\n",
    "- **Definition**: Assumption for causal inference.\n",
    "- **Components**:\n",
    "  - **No Interference**: Treatment of one unit doesn’t affect others.\n",
    "  - **Consistency**: Observed outcome under treatment matches potential outcome.\n",
    "- **Purpose**: Ensures valid causal effect estimation.\n",
    "\n",
    "### 3. **Sampling Distributions**\n",
    "- **Definition**: Distribution of a statistic (e.g., mean) from many samples drawn from the population.\n",
    "- **Key Concepts**:\n",
    "  - **Central Limit Theorem**: Sample means approach normal distribution as sample size increases.\n",
    "  - **Standard Error**: Measures variability of sample statistic.\n",
    "\n",
    "### 4. **Hypothesis Testing**\n",
    "- **Definition**: Method to infer population parameters based on sample data.\n",
    "- **Components**:\n",
    "  - **Null Hypothesis (H0)**: No effect or difference.\n",
    "  - **Alternative Hypothesis (H1)**: Contradicts H0.\n",
    "  - **Test Statistic**: Value calculated from data.\n",
    "  - **P-value**: Probability of observing the data under H0.\n",
    "  - **Decision**: Reject or fail to reject H0 based on p-value and significance level.\n",
    "\n",
    "### 5. **Bayesian Testing**\n",
    "- **Definition**: Updating the probability of a hypothesis using Bayes' theorem.\n",
    "- **Components**:\n",
    "  - **Prior Probability**: Initial probability before data.\n",
    "  - **Likelihood**: Probability of data given hypothesis.\n",
    "  - **Posterior Probability**: Updated probability after data.\n",
    "  - **Bayes' Theorem**: Calculates posterior from prior and likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
